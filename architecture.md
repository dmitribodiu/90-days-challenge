# ■■■ Day 6 
# Software architecture patterns >>>>>
# Layered architecture
Components within the layered architecture pattern are organized
into horizontal layers, each layer performing a specific role within
the application.
One of the powerful features of the layered architecture pattern is
the `separation of concerns` among components

## Key concepts
1. Layers of isolation
    Means that each layer can only impact layers that are directly besides it.
2. Opened layers
    Some layers (e.g service layers) can be open, meaning you don't need to 
    access them in order to access the layers below.

The layered architecture pattern is a solid general-purpose pattern,
making it a good starting point for most applications

## Drawbacks
1. architecture sinkhole anti-pattern
    When requests flow through multiple layers as simple pass-through 
    with little or no logic performed.
2. Layered architecutre tends to lend itself towards monolithic applications.
    It may cause problems for some applcations.

## Properties
1. Agility - low
    Cumbersome to make changes because of a monolithic nature of the pattern.
2. Ease of deployment - low
    Deployment may become an issue for larger apps.
    `Bad for CI pipeline`.
3. Testability - high
    Closed layers are easy to test because it's easy to mock other layers.
4. Performance - low
    Request has to go throught multiple layers which is not efficient.
5. Scalability - low
    Because of tightly couple tendency of this pattern, apps built with it are
    generally difficult to scale.
6. Ease of development - high
    Because layered structure mimics company specialists, it's a default choice 
    for most of companies.

# Event-driven architecture 
The event-driven architecture pattern is a popular distributed
asynchronous architecture pattern used to produce highly `scalable`
applications.

The event-driven architecture is made up of highly decoupled, single-purpose event
processing components that asynchronously receive and process events.

The event-driven architecture pattern consists of two main topologies,
the `mediator and the broker`.

## Mediator topology
The mediator topology is useful for events that have multiple steps
and require some level of orchestration to process the event.

There are four main types of architecture components within the
mediator topology: 
+ event queues
+ event mediator
+ event channels
+ event processors

There are two types of events within this pattern:
+ initial event
    original event received by mediator
+ processing event
    generated by the mediator and received by event processing components
    
For each step in the initial event, the event mediator sends out a specific
processing event to an event channel.

The `event processor` components contain the application business logic
necessary to process the processing event, they are idenpendent, `highly decoupled` 
components that perform a specific task in a system. Each processor should 
perform a single business task and not rely on other processors to complete their task.

## Broker
The broker topology differs from the mediator topology in that
there is no central event mediator, rather, the message flow is distributed
across the event processor components in a chain-like
fashion through a lightweight message broker. 

This topology is useful when you have a relatively
simple event processing flow

There are two main types of architecture components within the
broker topology: 
+ broker component 
+ event processor component.

The event channels contained within the broker component can be
message queues, message topics, or a combination of both.

the broker topology is all about the
`chaining of events to perform a business function`

once an event processor passes the event to another processor,
it is no longer involved with the processing of that specific event.

## Considerations
The event-driven architecture pattern is a relatively complex pattern to implement.
One consideration to take into account when choosing this architecture
pattern is the `lack of atomic transactions` for a single business process.

It is vitally important when
using this pattern to settle on a `standard data format` (XML/JSON)
and establish a contract versioning policy right from the start.

## Properties
1. Agility - high
    Since every process is completely decoupled from other processes, change can be made
    quickly.
2. Deployment - high
    Although broker is a little bit easier to deploy than mediator.
3. Testability - low
    You need special tool to generate events. Asynchronous nature of the pattern
    also adds up to the difficulty.
4. Performance - high
    Due to asynchronous nature is't very performant.
5. Scalability - high
    Each processor can be scaled separately which allows for fine-grained scalabiliyt.
6. Ease of development - low
    Why? 
    1. Async 
    2. Need for contract creation (JSON/XML scheme) 
    3. Complicated error handling of failed processors.

# Microkernel architecture
aka `plug-in` architecture pattern is a natural pattern for implementing
product-based applications (apps that are packaged and made available for download)

The microkernel architecture pattern allows you to add additional application
features as plug-ins to the core application, providing extensibility as well
as feature separation and isolation.

The microkernel architecture pattern consists of two types of components:
+ core system 
+ plug-in modules

The core system needs to know which plugins are available and how to get to them.
One way to implement that is through some sort of plug-in registry.
The patterns only specifies that these plugins should be independent from one another.

## Examples
Any IDE with plugins.
Browsers with plugins (Firefox, Chrome)

## Considerations
The microservices architecture pattern provides great support for
evolutionary design and incremental development. You can design the core system
and then as the app evolves add new features without having to make changes to the core
system.

For product-based applications, the microkernel architecture pattern
should always be your first choice. Particularly for products where you will be
releasing additional features and want control over which users get which features.

## Properties
1. Agility - high
    Changes can be isolated and implemented quickly via plug-ins.
2. Deployment - high
    Plugins can be added during runtime
3. Testability - high
    Plug-ins can be tested in isolation
4. Performance - high
    You can include only the plugins you need.
5. Scalability - medium
    Core system is not very scalable, although you can implement scalability on 
    the plug-in level
6. Ease Development - low
    This patterns requires thoughtful design and contract governance, making it 
    rather complex to implement.
    
# Microservices architecture pattern
Each component of this architecture is deployed as a separate unit.

`Service components` is an important notion in microservice architecture.
They contain one or more modules that represent either a single purpose function
or an independent portion of a large business app. 

Designing the right level of service component granularity is
one of the biggest challenges within a microservices architecture.

Another important notion is that microservices is a `distributed architecture`
all components are completely decoupled from one another and are accessed through 
some remote access protocol.

Microservices naturally evolved from layered architecutre and service-oriented 
pattern. This is the next step in patterns evolution.

When you deploy a monolitic application there's a high chance that something
will break. Wiht microservices on the other hand you can deploy more frequently 
and can have more confidence in release quality.

Microservices were designed to be easier than SOA to implement, it's attained
by simplifying connectivity and access to to service components.

## Topologies
In theory you can implement microservices however you want but 
the most common way to implement the patten is by using:
1. API REST based topology
    For websites with specific purposes. That contain of small services
    that implement some small self-contained portion of business logic.
2. application REST based topology
3. Centralized messaging topology
    Instead of using REST uses a `lightweight centralized message brocker`
    The `benefits` of this topology over the simple REST-based topology are:
    + advanced queuing mechanisms
    + asynchronous messaging
    + monitoring
    + error handling
    + better overall load balancing and scalability.
 
## Avoid dependencies and orchestration
One of the main challenges of the microservices architecture pattern
is determining the correct level of granularity for the service components.

If you find you need to orchestrate your components from user interface - your 
architecture is too fine-graned.
If you need to access multiple components within a single component - your components
are too large.

One way to prevent calling multiple components from within a component is 
to create a `shared database`. This way your services might have repeating 
code for database access, but it's a common practice,
you change redundancy of code for decoupling.

## Properties
1. Agility - high
    App built with this pattern tend to be very loosely coupled.
2. Ease of deployment - high
    Easy to deploy due to decoupled nature of pattern
3. Testability - high
    Due to separation of business logic into small components, they are easy to test.
4. Performance - low
    Due to distributed nature of the pattern it's usually not very performant.
5. Scalability - high
    Each component can be individually scaled.
6. Ease of development - high
    High decoupling -> easy development

# Space-based architecture (aka cloud architecture)
Usually architectures are hard to scale.
The space-based architecture pattern is specifically designed to
address and solve scalability and concurrency issues.

The space-based pattern (cloud architecture pattern)
minimizes the factors that limit application scaling

High scalability is achieved by removing the central database constraint and using
replicated in-memory data grids instead.
Because there is no central database, the database bottleneck is
removed, providing near-infinite scalability within the application.

The space-based architecture pattern is a complex and expensive
pattern to implement. It is a good architecture choice for smaller
web-based applications with variable load

However, it is not well suited for traditional
large-scale relational database applications with large amounts
of operational data.

# ■■■ Day 7
# Righting software >>>>>
# Intro
In general design is not time-consuming. If you allocate too much time
for design you risk to add to design things that add nothing but complexity to the design.
Limiting the design time forces you to produce `good-enough` design.

## Eliminating analysis paralysis
1. Design decision `trees`
    Each leaf should be a consistent, distinct and valid solution for a requirement.
    
    When you try to make a new desision about architecture from scratch you
    do something like `bubble sort` which is highly inefficient because it
    doesn't account for previous desisions.
2. Software system design decision tree
    Only after you have designed the system there's a point in designing a project
    to build that system.

    One of the most valuable techniques to decrease the size of a decision tree
    is the application of `constraints`. If you don't have constraints you have
    too many options which is bad (you will spend a lot of time too choose)
    With enough amount of constraints you don't need to design anything, it is what it 
    is.
    
> The clean canvas is the words design problem. (no constraints)

# System Design <<<
# Desomposition
While designing the system is quick and inexpensive compared with building the system,
it is critical to get the architecture right.

The correct decomposition is critical. A wrong decomposition means wrong architecture.
In modern systems `services` are the most granular unit of the architecture.
However, the technology used to implement the components and their details
are detailed design aspects, not system decomposition. 

## Avoid functional decomposition
Functional decomposition decomposes a system into its building
blocks based on the functionality of the system. (Like creating a distinct service
for every operation you need to perform e.g : billing, shipping, checkout)
`Why avoid?`
1. It couples services to the requirements, any change in functionality imposes a change 
    on a service. Functional decomposition precludes reuse
    (you won't be able to use this service in another system)
    and leads to overly compolex systems
    (if you choose to create a single service match-all)

    Functional decomposition, therefore, tends to make services either too big and too few
    or too small and too many. You often see both afflictions in the same system.

2. Clients bloat and coupling
    Functional decomposition often leads to flattening of the system hierarchy.
    Since each service serves specific functionality, someone has to combine these
    discrete functionalities into a required behaviour. That someone is often the client.

    By bloating the client with the orchestration logic,
    you pollute the client code with the business logic of sequencing, ordering,
    error compensation, and duration of the calls to the services. Which prevents
    you from ability to `evolve` client and services `independently`.
    Ultimately, the client is no longer the client—it has become the system.
    
    If there are multiple clients you are destined to duplicate that orchestration 
    logic on all clients making maintenance of all those clients wasteful and expensive.
    As the functionality changes, you now are forced to keep up with that change across
    multiple clients, since all of them will be affected.

3. Multiple points of entry
    Another problem of functional decomposition is that it requires 
    multiple points of entry to the system. The clients need to enter the system 
    in three places: once for the A, then for the B, then for the C service.
    When you will need to change any of these aspects you will need to change it 
    in multiple places across services and clients.

4. Services bloating and coupling
    You can think of letting services call one another instead of multiple points
    of entry for a client. This way you leave only one way of entry for a client 
    which might seem much better.
    The `problem` now is that the functional services are coupled to each
    other and to the `order` in which every service calls each other.

    When you let services know about one another and about order
    in which they should be invoked you couple them so tightly that 
    they become on big fused mess of a service.
    
## Reflecting on functional decomposition
Functional decomposition seems like the perfect way to design a system.
No wonder why so many systems are designed this way.
At all costs, you must `resist the temptations` of functional decomposition.

> Nature of the U niverse
    Functional desomposition is ineffective because it's so simple: just 
    divide the system into requirements and you are done. You can't make a good 
    architecture without breaking a sweat.

Functional decomposition has it's place when trying to figure out requirements 
from the customer. However there should `never` be direct mapping between the
requirements and the design.
    
## Avoid domain decomposition
Domain decomposition is decomposing a system into building blocks
based on the business domains. The reason domain decomposition does not work is that
it is still functional decomposition in disguise.

1. Building a Domain house
    Imagine completely finishing building a single room, you have one room
    with electricity, water and apartment repair. Then you go to your customer
    and show him "release 1.0". Then to build another room you need to `completely`
    rebuild the first one. 
    
    That's how domain decomposition works in pracitce. You can't just build single 
    domain components by themselves without proper architecture. Because if you 
    do, every time you introduce a new component you will likely need to rewrite 
    all other components which increases complexity to `!n`.

## Faulty motivation
The motivation for functional or domain decomposition is that
the business or the customer wants its feature as soon as possible.
The problem is that `you can never deploy a single feature in isolation`.

## Testability and design
A crucial flaw of both functional and domain decomposition has to do with testing. 
With such designs, the level of coupling and complexity is so high
that the only kind of testing developers can do is unit testing. 
The sad reality is that unit testing is borderline `useless`. While unit testing is
an essential part of testing, it cannot really test a `system`.

even if the complex system is at a perfect state of impeccable quality,
changing a single, unit-tested component could break
some other unit relying on an old behavior.

The only way to verify change is `full regression testing` of the system
But functional decomposition makes the entire system untestable in terms of 
regression testing (because with so many units it's hard to create a complete list 
of regression tests), and untestable systems are always rife with defects.

## Physical versus software systems
The main difference between physical and software systems is that when person
builds a physical thing it't obvious to everyone whether the thing is well architected
or not. But with software it's not so obvious. Bad architechture is being maintained
by less experienced engineers, slowing down their growth and in some cases ruining their
careers. 

## Example: Functional Trading System
If you design components so that client has to orchestrate them, every change in
any component will likely affect the client as well. Whatever change you may want to 
make will cause substantional rewrite of the existing system.

## Volatility-based decomposition
`Decompose based on volatility`.

Volatility-based decomposition identifies `areas of potential change` and
encapsulates those into services or system building blocks. You then implement
the required behavior as the interaction between the encapsulated areas of volatility

With volatility-based decomposition you can think of your system as of series of vaults
that contain granates (changes) than may potentially cause problems to your app.

With functional decomposition, your building blocks represent
areas of functionality, not volatility so when change happens it may affect multiple
components in your architecture. Functional decomposition doesn't account for `changes`.

## Decomposition, maintenance and development
As explained previously, functional decomposition drastically increases the
system’s complexity. Functional decomposition also makes maintenance a `nightmare`.
It makes maintaining the code labor intensive, error prone, and very time-consuming. 
Even during development it may easily break your deadline because changes are often made
even while development.

## Universal principle
The merits of volatility-based decomposition are not specific to software systems. 
A functional decomposition of your own body would have components for every
task you are required to do, from driving to programming to presenting,
yet your body does not have any such components. 

> Decomposing based on `volatility` is the essence of system design.

All well-designed systems, software and physical systems alike,
encapsulate their volatility inside the system’s building blocks.

## Volatility-Based Decomposition and Testing
Volatility-based decomposition lends well to `regression` testing as well as unit testing.
The reduction in the number of components, the reduction in the size of components,
and the simplification of the interactions between components all drastically
reduce the complexity of the system. 

## The Volatility Challenge
The main challenges in performing a volatility-based decomposition have to do with
+ time
+ communication
+ perception.

The outside world (be it customers, management, or marketing) always presents
you with requirements in terms of functionality: “The system should do this and that.”
Consequently, `volatility-based decomposition takes longer`
compared with functional decomposition

The whole purpose of requirements analysis is to `identify the areas of volatility`
and this analysis requires effort and sweat.

## The 2% problem








































